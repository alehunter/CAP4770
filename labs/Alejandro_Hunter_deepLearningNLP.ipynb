{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alehunter/CAP4770/blob/main/labs/Alejandro_Hunter_deepLearningNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hHAxGRCXb7X_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291bc76f-cdd4-47a1-825d-53f0cb42176a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 15 16:49:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    46W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omp4N9HXb-b4"
      },
      "source": [
        "\n",
        "# Deep Learning for Natural Language Processing\n",
        "\n",
        "Natural Language Processing (NLP) covers machine learning techniques dealing with text and includes\n",
        "\n",
        "* classification\n",
        "  * sentiment analyis (is this tweet a Pro-Biden or Anti-Biden one)\n",
        "  * stylometrics (was this typed suicide note really from the deceased or did the murderer write it [1](https://www.rosette.com/case-studies/alias/), [2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3107011/)\n",
        "  * general classification (out of 40 topics, which is this article about)\n",
        "* question answering (building systems that can answer questions -- *What is the best treatment for hemangiosarcoma in dogs?*)\n",
        "* machine translation\n",
        "* speech recognition\n",
        "\n",
        "among many others. Deep Learning has led to tremendous improvements in all these areas of NLP. \n",
        "\n",
        "In this notebook, we are going to examine classification systems for textual information.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm5JKEGBvFZH"
      },
      "source": [
        "\n",
        "## Analyzing and Classifying Text\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/tiles.jpg\" width=\"500\"/>\n",
        "\n",
        "So far we have been dealing with **structured data**. Structured data is ... well ... structured. This means that an instance of our data has nice attributes that can be represented in a DataFrame or a table:\n",
        "\n",
        "make | mpg | cylinders | HP | 0-60 |\n",
        "---- | :---: | :---: | :---: | :---: |\n",
        "Fiat | 38 | 4 | 157   | 6.9 \n",
        "Ford F150 | 19 | 6 | 386 | 6.3 \n",
        "Mazda 3 | 37 | 4 | 155 |  7.5 \n",
        "Ford Escape | 27 | 4 | 245 | 7.1 \n",
        "Kia Soul | 31 | 4 | 164 | 8.5 \n",
        "\n",
        "The majority of data in the world is **unstructured**. Take text for example. Suppose I have a corpus of twitter posts from former president Donald Trump and the Dalai Lama and my goal is to create a classifier that takes a tweet and tells me if it was produced by Trump or the Dalai Lama:\n",
        "\n",
        "*The purpose of education is to build a happier society, we need a more holistic approach that promotes the practice of love and compassion.*\n",
        "\n",
        "*How low has President Obama gone to tapp my phones during the very sacred election*\n",
        "\n",
        "We might consider  the columns of a table to be things like *first word of the tweet*, *second word of the tweet* and so on:\n",
        "\n",
        "\n",
        "id | word 1 | word 2 | word 3 | word 4 |word 5 |word 6 | ... |\n",
        "---- | :---: | :---: | :---: | :---: | :---: |:---: |:---: |\n",
        "1 | The | purpose | of   | education |is | to | ...\n",
        "2 | How | low | has |President | Obama | gone | ...\n",
        "\n",
        "So we would be counting how many times the word *President* occurred as the fourth word of a tweet. **But that would be the wrong way to go**. First, the deep learning models we have developed so far require input of a specific length. For example, we resized our dog and cat images to a uniform 150x150 and because each image was a uniform size we could specify the input shape of our network to be ....\n",
        "\n",
        "```\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "```\n",
        "\n",
        "But what should the input length be for tweets? Sometimes there are short, one-word, tweets like *nice*. The average length of a tweet is 30 characters so something like the six word *Today, Toaster is 10 years old.*  And the limit of course is 280 characters so...\n",
        "\n",
        "> Like anything else, life has a beginning and in due course must end. In between those two events the important goal should be to live meaningfully, not to create trouble for others. If we can do that, when the end comes, we can go feeling at peace.\n",
        "\n",
        "That's 47 words so maybe we can limit our input to 50 words and for shorter tweets we can pad them with blank words.  But there is another possibility ...\n",
        "\n",
        "### Bag of Words (bow)\n",
        "\n",
        "A more common way to represent text is to treat the text as an unordered set of words, which is called the **bag of words** approach. \n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/BagofWords.jpg\" width=\"350\"/>\n",
        "\n",
        "With the bag of words approach we count word occurrences and the features (what we might think of as columns) are the unique words. For example, we have a collection of Trump and Dalai Lama tweets and indicate whether the word occurred in the tweet or not. So we might get something like:\n",
        "\n",
        "id | a | the | compassion | love |sad |fake | rigged | ... |\n",
        "---- | :---: | :---: | :---: | :---: | :---: |:---: |:---: | :---:\n",
        "Trump_1 | 1 | 0 | 0   | 0 |1 | 1 | 1 |...\n",
        "Trump_2 | 1 | 1 | 0   | 0 | 0 | 1 | 1 |...\n",
        "DalaiLama_1 | 1 | 1 | 1 |1 | 0 | 0 | 0 | ...\n",
        "\n",
        "So, for example, in DalaiLama_1, in the text there was\n",
        "\n",
        "* an occurrence of *a*\n",
        "* an occurrence of *the*\n",
        "* an occurrence of *compassion*\n",
        "* an occurrence of *love*\n",
        "\n",
        "We don't know what order the words occurred in, we just know what words occurred in the tweet. This is the bag-of-words method. \n",
        "\n",
        "Instead of short text snippets like tweets, let's say we are analyzing speeches of Trump and the Dalai Lama. Maybe then we will count how many times they used each word. So something like:\n",
        "\n",
        "id | a | the | compassion | love |sad |fake | rigged | ... |\n",
        "---- | :---: | :---: | :---: | :---: | :---: |:---: |:---: | :---:\n",
        "Trump_1 | 52 | 25 | 0   | 0 |21 | 82 | 19 |...\n",
        "Trump_2 | 30 | 35 | 0   | 0 | 5 | 20 | 31 |...\n",
        "DalaiLama_1 | 60 | 271 | 27 |63 | 12 | 0 | 0 | ...\n",
        "\n",
        "Of course we are still faced with how many columns to make, representing the vocabulary size. We could limit it to the 10,000 most common words, for example.\n",
        "\n",
        "Once we have the text in this format we can use the standard deep learning classification techniques we used before.\n",
        "\n",
        "\n",
        "Converting **unstructured** text to something **structured** is a multistep process. Let's learn the bits before putting it together. And we will start with the last step first-- creating the bag of words.\n",
        "\n",
        "### Import Keras ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-igfitKjuYru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e9c420ce-8d98-4963-f926-32dca3e9c4a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1153Guw8wB_"
      },
      "source": [
        "### Some sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u1mf095J8u_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b705d38-d498-42a4-e83c-25a3325273f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How low has President Obama gone to tapp my phones during the very sacred election process. This is Nixon/Watergate. Obama bad (or sick) guy! Sad',\n",
              " 'Our wonderful new Healthcare Bill is now out for review and negotiation. ObamaCare is a complete and total disaster - is imploding fast! Sad',\n",
              " \"Don't let the FAKE NEWS tell you that there is big infighting in the Trump Admin. We are getting along great, and getting major things done!\",\n",
              " 'Russia talk is FAKE NEWS put out by the Dems, and played up by the media, in order to mask the big election defeat and the illegal leaks! Sad',\n",
              " 'The purpose of education is to build a happier society, we need a more holistic approach that promotes the practice of love and compassion.',\n",
              " 'Be a kind and compassionate person. This is the inner beauty that is a key factor to making a better world.',\n",
              " 'If our goal is a happier, more peaceful world in the future, only education will bring change.',\n",
              " 'Love and compassion are important, because they strengthen us. This is a source of hope']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "trump1 = \"How low has President Obama gone to tapp my phones during the very sacred election process. This is Nixon/Watergate. Obama bad (or sick) guy! Sad\"\n",
        "trump2 = \"Our wonderful new Healthcare Bill is now out for review and negotiation. ObamaCare is a complete and total disaster - is imploding fast! Sad\"\n",
        "trump3 = \"Don't let the FAKE NEWS tell you that there is big infighting in the Trump Admin. We are getting along great, and getting major things done!\"\n",
        "trump4 = \"Russia talk is FAKE NEWS put out by the Dems, and played up by the media, in order to mask the big election defeat and the illegal leaks! Sad\"\n",
        "dalaiLama1 = \"The purpose of education is to build a happier society, we need a more holistic approach that promotes the practice of love and compassion.\"\n",
        "dalaiLama2 = \"Be a kind and compassionate person. This is the inner beauty that is a key factor to making a better world.\"\n",
        "dalaiLama3 = \"If our goal is a happier, more peaceful world in the future, only education will bring change.\"\n",
        "dalaiLama4 = \"Love and compassion are important, because they strengthen us. This is a source of hope\"\n",
        "tinyCorpus = [trump1, trump2, trump3, trump4, dalaiLama1, dalaiLama2, dalaiLama3, dalaiLama4]\n",
        "tinyCorpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-y3dlin89du"
      },
      "source": [
        "### Create the bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LrWO8riu80Bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6bf0c0-044e-4a5c-f1ee-47af87f14dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Found 117 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=200)\n",
        "tokenizer.fit_on_texts(tinyCorpus)\n",
        "\n",
        "# Directly get the one-hot binary representations.\n",
        "# Note that other vectorization modes than one-hot encoding are supported!\n",
        "one_hot_results = tokenizer.texts_to_matrix(tinyCorpus, mode='binary')\n",
        "# let's look at an example of an encoding ...\n",
        "print(one_hot_results[0])\n",
        "\n",
        "\n",
        "# This is how you can recover the word index that was computed\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p13Daqp__dfB"
      },
      "source": [
        "That was pretty easy. And now we have the texts in a form we can use for deep learning.\n",
        "\n",
        "Instead of the binary choice (a 1 if the word is present and a 0 if not) -- `mode='binary'` we can count how many occurrences of each word there were in the text by using `mode='count'`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GgOPTdZf_sBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903119cb-6128-45d2-c9b3-63036c49d516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 3. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "one_hot_results = tokenizer.texts_to_matrix(tinyCorpus, mode='count')\n",
        "# let's look at an example of an encoding ...\n",
        "print(one_hot_results[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skKDJALg_-Is"
      },
      "source": [
        "So in the first tweet:\n",
        "\n",
        "> 'Our wonderful new Healthcare Bill is now out for review and negotiation. ObamaCare is a complete and total disaster - is imploding fast! Sad',\n",
        "\n",
        "There were 3 occurrences of the word *is*, 2 of *and*, and so on as indicated in the first row above.\n",
        "\n",
        "How do we know what columns are associated with which words? We can use the word_index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HwaZVV8fAMnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5729b9b-5ece-4691-9ca3-24f760793c44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 1),\n",
              " ('is', 2),\n",
              " ('and', 3),\n",
              " ('a', 4),\n",
              " ('to', 5),\n",
              " ('this', 6),\n",
              " ('sad', 7),\n",
              " ('that', 8),\n",
              " ('in', 9),\n",
              " ('of', 10),\n",
              " ('obama', 11),\n",
              " ('election', 12),\n",
              " ('our', 13),\n",
              " ('out', 14),\n",
              " ('fake', 15),\n",
              " ('news', 16),\n",
              " ('big', 17),\n",
              " ('we', 18),\n",
              " ('are', 19),\n",
              " ('getting', 20),\n",
              " ('by', 21),\n",
              " ('education', 22),\n",
              " ('happier', 23),\n",
              " ('more', 24),\n",
              " ('love', 25),\n",
              " ('compassion', 26),\n",
              " ('world', 27),\n",
              " ('how', 28),\n",
              " ('low', 29),\n",
              " ('has', 30),\n",
              " ('president', 31),\n",
              " ('gone', 32),\n",
              " ('tapp', 33),\n",
              " ('my', 34),\n",
              " ('phones', 35),\n",
              " ('during', 36),\n",
              " ('very', 37),\n",
              " ('sacred', 38),\n",
              " ('process', 39),\n",
              " ('nixon', 40),\n",
              " ('watergate', 41),\n",
              " ('bad', 42),\n",
              " ('or', 43),\n",
              " ('sick', 44),\n",
              " ('guy', 45),\n",
              " ('wonderful', 46),\n",
              " ('new', 47),\n",
              " ('healthcare', 48),\n",
              " ('bill', 49),\n",
              " ('now', 50),\n",
              " ('for', 51),\n",
              " ('review', 52),\n",
              " ('negotiation', 53),\n",
              " ('obamacare', 54),\n",
              " ('complete', 55),\n",
              " ('total', 56),\n",
              " ('disaster', 57),\n",
              " ('imploding', 58),\n",
              " ('fast', 59),\n",
              " (\"don't\", 60),\n",
              " ('let', 61),\n",
              " ('tell', 62),\n",
              " ('you', 63),\n",
              " ('there', 64),\n",
              " ('infighting', 65),\n",
              " ('trump', 66),\n",
              " ('admin', 67),\n",
              " ('along', 68),\n",
              " ('great', 69),\n",
              " ('major', 70),\n",
              " ('things', 71),\n",
              " ('done', 72),\n",
              " ('russia', 73),\n",
              " ('talk', 74),\n",
              " ('put', 75),\n",
              " ('dems', 76),\n",
              " ('played', 77),\n",
              " ('up', 78),\n",
              " ('media', 79),\n",
              " ('order', 80),\n",
              " ('mask', 81),\n",
              " ('defeat', 82),\n",
              " ('illegal', 83),\n",
              " ('leaks', 84),\n",
              " ('purpose', 85),\n",
              " ('build', 86),\n",
              " ('society', 87),\n",
              " ('need', 88),\n",
              " ('holistic', 89),\n",
              " ('approach', 90),\n",
              " ('promotes', 91),\n",
              " ('practice', 92),\n",
              " ('be', 93),\n",
              " ('kind', 94),\n",
              " ('compassionate', 95),\n",
              " ('person', 96),\n",
              " ('inner', 97),\n",
              " ('beauty', 98),\n",
              " ('key', 99),\n",
              " ('factor', 100),\n",
              " ('making', 101),\n",
              " ('better', 102),\n",
              " ('if', 103),\n",
              " ('goal', 104),\n",
              " ('peaceful', 105),\n",
              " ('future', 106),\n",
              " ('only', 107),\n",
              " ('will', 108),\n",
              " ('bring', 109),\n",
              " ('change', 110),\n",
              " ('important', 111),\n",
              " ('because', 112),\n",
              " ('they', 113),\n",
              " ('strengthen', 114),\n",
              " ('us', 115),\n",
              " ('source', 116),\n",
              " ('hope', 117)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# tokenizer.word_index is a python dictionary containing the word as a key and the column as its value\n",
        "[(k, v) for k, v in sorted(tokenizer.word_index.items(), key=lambda item: item[1])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-F8umxI-JnV"
      },
      "source": [
        "So, *the, is, and, a, to* are the words represented by the first five columns.\n",
        "\n",
        "\n",
        "# TF-IDF representation\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/bigTFIDF.png)\n",
        "So far we looked at \n",
        "\n",
        "* a binary bag-of-words (whether or not the word was present in the text).\n",
        "* a raw count bag-of-words (counting how many occurrences of each word)\n",
        "\n",
        "There are several other approaches\n",
        "We could represent a document as a bag of words and their probabilities (`mode=\"freq\"`). For example, in *Tom Sawyer* 4.6% of the words are *the* and 0.95% are *Tom*. But the word *the* probably occurs in most novels with that frequency. So in some sense the word *the* is uninteresting. On the other hand *Tom* probably occurs much more frequently in *Tom Sawyer* than it does in *Moby Dick* and, in that way, it is a more interesting word. One way to discount words that occur evenly throughout our document collection is to use TF-IDF.  \n",
        "\n",
        "* TF: Term Frequency - each word uprated by how often the word occurs in the document.\n",
        "* IDF Inverse Document Frequency - how often the word appears in the entire corpus\n",
        "\n",
        "\n",
        "\n",
        "> TF-IDF was first proposed by Karen Sparck Jones as a heuristic--not having any theoretical foundation. Researchers since then have tried to justify this metric by relating it to probablistic theories and information theories. But these attempts have been problematic. Nevertheless, as we will see, this heuristic works quite well. \n",
        "\n",
        "The formula is\n",
        "\n",
        "### $$ tfidf(t, d) = tf(t,d) \\times idf(t) $$\n",
        "\n",
        "where *t* is the term (the word) and *d* is the document.\n",
        "\n",
        "To explain this I will use some made up data--the word counts of 5 emails (and for the sake of later computations let's assume that each email is 100 words long):\n",
        "\n",
        "id | the | sad | compassion |  \n",
        "----: | :---: | :---: | :---:\n",
        "1 | 3 | 0 | 1 \n",
        "2 | 3 | 0 | 0 \n",
        "3 | 4 | 0 | 0 \n",
        "4 | 3 | 2 | 0 \n",
        "5 | 3 | 0 | 2\n",
        "\n",
        "\n",
        "The intuition is this. Even though the word *the* occurs frequently in each email, it is unlikely to help us classify email because it occurs in **every** email. The words *sad* and *compassion* are more interesting as they don't occur uniformly in our collection. \n",
        "\n",
        "#### TF\n",
        "\n",
        "The TF part of TF-IDF refers to how often the word occurs in the document. There are a number of ways to define TF. The simplist is to use the raw count.  So for example, the TF of *the* in document 1 is 3 (the word *the* occurred 3 times in document 1). One problem with this approach is that the raw count is influenced by the length of the document. So if you in your 1,000 word essay on Tom Sachs use 50 occurrences of *the* and Jane in her 90,000 word Zen van life mystery novel use 4,5000 occurrences of *the*, it doesn't mean that Jane is a bigger fan of *the* than you are. Even though there is that disparity in the raw counts it is not a characteristic that will help us distinguish texts about Zen from those about Tom Sachs.  In both the 1,000 word essay and the 90,000 word book about 5% of the words are *the*. A popular measure of TF is to divide the number of occurrences of a word by the total words in the document. So the TF of the word *the* in both your 1,000 word essay and my novel would be .05\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### IDF\n",
        "\n",
        "IDF is defined as:\n",
        "\n",
        "### $$ idf(t)=\\log\\frac{1+n_d}{1+df(d,t)}+ 1 $$\n",
        "\n",
        "$n_d$ is the total number of documents and $df(d,t)$ is how many documents the term *t* occurred in. \n",
        "\n",
        "So:\n",
        "\n",
        "### $$ idf(the)=\\log\\frac{1+5}{1+5}+ 1 =  1.5 $$\n",
        "\n",
        "### $$ idf(compassion)=\\log\\frac{1+5}{1+2}+ 1 = \\log{2} + 1 =  2 $$\n",
        "\n",
        "So, *the* in document 1 has a tf-idf of $.03 \\times 1.5 = 0.045$ and *compassion* has a tf-idf of $.01 \\times \\ 2 = 0.02$\n",
        "\n",
        "This is a fairly important concept to understand. I was asked about tf-idf in my oral exam to become a certified instructor at the Deep Learning Institute and fortunately I knew about it. \n",
        "\n",
        "It is also important to know that while it works well as a heuristic and has been around since the 70s, there really is no theoretical foundation to it. \n",
        "\n",
        "With all that as background, it is easy to convert a document collection into an array of TFIDF values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-KVXgJ3R9Pmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6f9776-6fbd-4f93-d50e-3a839fc81ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         1.33469384 1.29041528 0.84729786 0.\n",
            " 0.         1.09861229 0.         0.         0.         0.\n",
            " 0.         1.29928298 1.29928298 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         1.60943791 1.60943791\n",
            " 1.60943791 1.60943791 1.60943791 1.60943791 1.60943791 1.60943791\n",
            " 1.60943791 1.60943791 1.60943791 1.60943791 1.60943791 1.60943791\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "one_hot_results = tokenizer.texts_to_matrix(tinyCorpus, mode='tfidf')\n",
        "# let's look at an example of an encoding ...\n",
        "print(one_hot_results[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTRonUNXFZRj"
      },
      "source": [
        "Again, once we have this representation we can use the deep learning methods we already used.\n",
        "\n",
        "\n",
        "## An initial example - IMDB\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/imdb.png)\n",
        "\n",
        "The Internet Movie DataBase consists of 50,000 movie reviews and contains an equal number of positive and negative reviews. The task of identifying the affect of a text (whether it is postive or negative, or how strongly someone feels about the topic) is called **sentiment analysis**. \n",
        "\n",
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xLDR_eiY1YCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b98e907-b200-4515-e3fd-a2838947527c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-15 16:49:57--  http://zacharski.org/files/courses/cs419/imdb.zip\n",
            "Resolving zacharski.org (zacharski.org)... 198.199.65.227\n",
            "Connecting to zacharski.org (zacharski.org)|198.199.65.227|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26559010 (25M) [application/zip]\n",
            "Saving to: ‘imdb.zip’\n",
            "\n",
            "imdb.zip            100%[===================>]  25.33M  54.0MB/s    in 0.5s    \n",
            "\n",
            "2022-11-15 16:49:58 (54.0 MB/s) - ‘imdb.zip’ saved [26559010/26559010]\n",
            "\n",
            "Archive:  imdb.zip\n",
            "  inflating: imdb.csv                \n"
          ]
        }
      ],
      "source": [
        "!wget http://zacharski.org/files/courses/cs419/imdb.zip\n",
        "!unzip imdb.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YLkosiEaRc2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07621fbf-d9a5-46c0-f263-a31cd7d93ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 90608\n",
            "-rw-r--r-- 1 root root 66212309 Oct 31  2020 imdb.csv\n",
            "-rw-r--r-- 1 root root 26559010 Oct 31  2020 imdb.zip\n",
            "drwxr-xr-x 1 root root     4096 Nov 11 14:32 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnWmyR3rgK6"
      },
      "source": [
        "The zip file only contained one file so we could have read it directly.  Since we already unzipped it let's use the unzipped version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T0tpCqv_BkWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "33749732-6e35-4398-d680-224fabfa97e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61e4dacf-f05a-4029-ba55-2ad1fbd90dec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61e4dacf-f05a-4029-ba55-2ad1fbd90dec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61e4dacf-f05a-4029-ba55-2ad1fbd90dec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61e4dacf-f05a-4029-ba55-2ad1fbd90dec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('imdb.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg97QeqW2KoT"
      },
      "source": [
        "Now let's separate the texts from the labels. Also note that the labels are the strings *positive* and *negative* so let's convert those to 1 and 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ql-GmhdXLShN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2a13c0-e324-4187-b5c6-bb6ff9fb4817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "49995    1\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    0\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data_text = data.review\n",
        "data_label =data.sentiment\n",
        "data_label =  data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "data_label "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXn9kHUb2cn1"
      },
      "source": [
        "### TFIDF\n",
        "Now we are going to convert the text represented as strings to a tfidf representation. \n",
        "\n",
        "Let's use the 5,000 most common words in the documents (`Tokenizer(num_words=5000)`)\n",
        "\n",
        "This will take a bit of time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XOjTzQdOJz-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f34338c-0fd5-458f-919e-9f021441a41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         2.63159248 1.98374445 ... 0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(data_text)\n",
        "\n",
        "# Directly get the one-hot binary representations.\n",
        "# Note that other vectorization modes than one-hot encoding are supported!\n",
        "one_hot_results = tokenizer.texts_to_matrix(data_text, mode='tfidf')\n",
        "# let's look at an example of an encoding ...\n",
        "print(one_hot_results[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC35HHYgbUqW"
      },
      "source": [
        "###  Divide into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dbPLee2_MJEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0627d6b0-2c28-4b84-b3a5-5968c13abfb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33553    1\n",
              "9427     1\n",
              "199      0\n",
              "12447    1\n",
              "39489    0\n",
              "        ..\n",
              "28567    0\n",
              "25079    1\n",
              "18707    1\n",
              "15200    0\n",
              "5857     1\n",
              "Name: sentiment, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "imdb_train_text, imdb_test_text, imdb_train_labels, imdb_test_labels = train_test_split(one_hot_results, data_label, test_size = 0.2, random_state=42)\n",
        "imdb_test_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04NGZqtVdOpF"
      },
      "source": [
        "### Build a deep learning model\n",
        "Let's go with a basic, no frills, model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lj35GJladKJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bd50eafa-3adf-4cf7-e6dd-ef17e59bb345"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3BxwR6u3YnG"
      },
      "source": [
        "In our tokenizer we specified a vocabulary size of 5,000 words, so that is our `input_shape`. We are trying to predict a binary 1,0 classification so we need \n",
        "\n",
        "```\n",
        "network.add(layers.Dense(1, activation='sigmoid'))\n",
        "```\n",
        "at the very end of our network. \n",
        "\n",
        "We would like a network with\n",
        "\n",
        "1. a dense layer with 512 nodes and input shape (5000,)\n",
        "2. a dense layer of 256\n",
        "3. A dense layer of 128\n",
        "4. A dense layer (the output layer) of 1 with the sigmoid activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4Pb3pBO7dpS4"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(5000,)))\n",
        "network.add(layers.Dense(256, activation='relu'))\n",
        "network.add(layers.Dense(128, activation='relu'))\n",
        "network.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tqZ-8UO30wu"
      },
      "source": [
        "Again, we are predicting a binary 1,0 classification (was it a positive review or not) so we will use `binary_crossentropy` as our loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nNchu2tmerGA"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "network.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F5PiezmrexYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650997bf-e155-46c0-eff8-c0598b0fdbbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               2560512   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,724,865\n",
            "Trainable params: 2,724,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "network.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTbirosf4JSO"
      },
      "source": [
        "### fitting to the data\n",
        "Now it is time to fit the network to the data. Let's use 20% of the data for validation and run for 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yEP-UYpIe2Vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f701f44-887c-4d9a-e811-18349858b0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 5s 9ms/step - loss: 0.4314 - accuracy: 0.8115 - val_loss: 0.3078 - val_accuracy: 0.8805\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2261 - accuracy: 0.9156 - val_loss: 0.3024 - val_accuracy: 0.8815\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1521 - accuracy: 0.9470 - val_loss: 0.3247 - val_accuracy: 0.8848\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1006 - accuracy: 0.9690 - val_loss: 0.3498 - val_accuracy: 0.8832\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0612 - accuracy: 0.9828 - val_loss: 0.3846 - val_accuracy: 0.8845\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0333 - accuracy: 0.9918 - val_loss: 0.4518 - val_accuracy: 0.8813\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.5368 - val_accuracy: 0.8817\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.6262 - val_accuracy: 0.8804\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.7557 - val_accuracy: 0.8811\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 8.3702e-04 - accuracy: 0.9998 - val_loss: 0.8871 - val_accuracy: 0.8771\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 4.2599e-04 - accuracy: 0.9999 - val_loss: 0.9486 - val_accuracy: 0.8792\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 2.3021e-04 - accuracy: 0.9999 - val_loss: 1.0041 - val_accuracy: 0.8798\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.2187e-04 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.8819\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.2114 - val_accuracy: 0.8810\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 6.3722e-06 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.8806\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 3.2808e-06 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.8811\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 7.6294e-07 - accuracy: 1.0000 - val_loss: 1.4872 - val_accuracy: 0.8814\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 2.4129e-07 - accuracy: 1.0000 - val_loss: 1.5658 - val_accuracy: 0.8814\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1461e-07 - accuracy: 1.0000 - val_loss: 1.6168 - val_accuracy: 0.8814\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 6.4501e-08 - accuracy: 1.0000 - val_loss: 1.6550 - val_accuracy: 0.8815\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 4.2162e-08 - accuracy: 1.0000 - val_loss: 1.6847 - val_accuracy: 0.8813\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 2.9715e-08 - accuracy: 1.0000 - val_loss: 1.7098 - val_accuracy: 0.8814\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 2.2531e-08 - accuracy: 1.0000 - val_loss: 1.7286 - val_accuracy: 0.8816\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.7801e-08 - accuracy: 1.0000 - val_loss: 1.7451 - val_accuracy: 0.8809\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.4682e-08 - accuracy: 1.0000 - val_loss: 1.7595 - val_accuracy: 0.8809\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.2405e-08 - accuracy: 1.0000 - val_loss: 1.7725 - val_accuracy: 0.8814\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.0717e-08 - accuracy: 1.0000 - val_loss: 1.7841 - val_accuracy: 0.8814\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 9.4251e-09 - accuracy: 1.0000 - val_loss: 1.7941 - val_accuracy: 0.8814\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 8.4080e-09 - accuracy: 1.0000 - val_loss: 1.8029 - val_accuracy: 0.8813\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 7.5905e-09 - accuracy: 1.0000 - val_loss: 1.8110 - val_accuracy: 0.8808\n"
          ]
        }
      ],
      "source": [
        "history = network.fit(\n",
        "      imdb_train_text, imdb_train_labels,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_split=0.2,\n",
        "      validation_steps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1R-XCz-4gEN"
      },
      "source": [
        "### Our accuracy and loss\n",
        "Let's plot out both the training and validation accuracy and loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "x6oPJSbM4gW8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "3f04aed2-876c-4d35-c195-24ec328f74f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiqOLIsJ5bg8"
      },
      "source": [
        "What is your interpretation of the plots?\n",
        "\n",
        ". INTERPRETATION\n",
        "\n",
        ". The training accuracy and loss are mirrors of each other, as the accuracy got better, the loss went down. The Validation accuracy was relatively constant, while the validation loss went up by alot. These graphs likely show that the model has been highly fitted to the supplied data. \n",
        "\n",
        ". END INTERPRETATION\n",
        "\n",
        "\n",
        "Okay, that definitely looks like overfitting. We will examine ways of ameliorating overfitting shortly.  \n",
        "\n",
        "Let's see how our network performs on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Byb8BGdL8Xtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b618e54-e676-4781-e520-6af139dd2d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.8024 - accuracy: 0.8769\n",
            "Accuracy:  0.8769000172615051\n"
          ]
        }
      ],
      "source": [
        "scoreSeg = network.evaluate(imdb_test_text, imdb_test_labels)\n",
        "print(\"Accuracy: \", scoreSeg[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaPCNeGgrTdF"
      },
      "source": [
        "Not bad for our first attempt at text classification!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3Y8Ck5hCfYk"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/torchdivide.png)\n",
        "\n",
        "\n",
        "# <font color='#EE4C2C'>Climate Change ...</font> \n",
        "\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/factfake.jpeg)\n",
        "\n",
        "On Twitter there are people who deny climate change:\n",
        "\n",
        "> I don't know about you guys, but I think climate change is -- as Lord Monckton said -- bullsh*t\n",
        "\n",
        "and people who believe it is real:\n",
        "\n",
        "> Millennials, and Gen z, and all these folks that come after us, are looking up and we’re like ‘the world will end in 12 years if we don’t address climate change, and your biggest issue is how are we gonna pay for it?\n",
        "\n",
        "We are going to investigate the sentiment of tweets from the Twitter Climate Change Sentiment Dataset compiled by Edward Qian. The dataset consists of 43,943 tweets. Instead of a binary label (a positive sentiment on climate change or a negative, there are four possible labels:\n",
        "\n",
        "Label | Description\n",
        ":--- | :---- \n",
        "News | the tweet links to factual news about climate change\n",
        "Pro | the tweet supports the belief of man-made climate change\n",
        "Neutral |  the tweet neither supports nor refutes the belief of man-made climate change\n",
        "Anti | the tweet does not believe in man-made climate change\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>1. Load the data.</font> \n",
        "\n",
        "The file is \n",
        "\n",
        "https://raw.githubusercontent.com/zacharski/ml-class/master/data/climateSentiment.csv.zip\n",
        "\n",
        "You will need:\n",
        "\n",
        "* to load the file\n",
        "* convert the text of the tweet to a tf-idf representation. We will start with using the 5,000 most common words\n",
        "* convert the labels\n",
        "* divide into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gvC3tJUiCppb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d7db3a-9392-4f0d-dc89-795f233e7576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-15 16:51:05--  https://raw.githubusercontent.com/zacharski/ml-class/master/data/climateSentiment.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2589663 (2.5M) [application/zip]\n",
            "Saving to: ‘climateSentiment.csv.zip’\n",
            "\n",
            "climateSentiment.cs 100%[===================>]   2.47M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-11-15 16:51:05 (36.5 MB/s) - ‘climateSentiment.csv.zip’ saved [2589663/2589663]\n",
            "\n",
            "Archive:  climateSentiment.csv.zip\n",
            "  inflating: climate.csv             \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/zacharski/ml-class/master/data/climateSentiment.csv.zip\n",
        "!unzip climateSentiment.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "10bOFMCa-2Y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5b12191a-c216-439e-8621-be2205c969dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sentiment                                            message  \\\n",
              "0          Anti  @tiniebeany climate change is an interesting h...   \n",
              "1           Pro  RT @NatGeoChannel: Watch #BeforeTheFlood right...   \n",
              "2           Pro  Fabulous! Leonardo #DiCaprio's film on #climat...   \n",
              "3           Pro  RT @Mick_Fanning: Just watched this amazing do...   \n",
              "4          News  RT @cnalive: Pranita Biswasi, a Lutheran from ...   \n",
              "...         ...                                                ...   \n",
              "43938       Pro  Dear @realDonaldTrump,\\nYeah right. Human Medi...   \n",
              "43939       Pro  What will your respective parties do to preven...   \n",
              "43940      News  RT @MikkiL: UN Poll Shows Climate Change Is th...   \n",
              "43941   Neutral  RT @taehbeingextra: i still can$q$t believe th...   \n",
              "43942       Pro  @Likeabat77 @zachhaller \\n\\nThe wealthy + foss...   \n",
              "\n",
              "                  tweetid  \n",
              "0      792927353886371840  \n",
              "1      793124211518832641  \n",
              "2      793124402388832256  \n",
              "3      793124635873275904  \n",
              "4      793125156185137153  \n",
              "...                   ...  \n",
              "43938  791307031919550464  \n",
              "43939  791316857403936768  \n",
              "43940  791357509101621249  \n",
              "43941  791390042136641537  \n",
              "43942  791401610308038656  \n",
              "\n",
              "[43943 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29c7795c-3583-41ca-8a63-e12ab963fb32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anti</td>\n",
              "      <td>@tiniebeany climate change is an interesting h...</td>\n",
              "      <td>792927353886371840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pro</td>\n",
              "      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right...</td>\n",
              "      <td>793124211518832641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pro</td>\n",
              "      <td>Fabulous! Leonardo #DiCaprio's film on #climat...</td>\n",
              "      <td>793124402388832256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pro</td>\n",
              "      <td>RT @Mick_Fanning: Just watched this amazing do...</td>\n",
              "      <td>793124635873275904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>News</td>\n",
              "      <td>RT @cnalive: Pranita Biswasi, a Lutheran from ...</td>\n",
              "      <td>793125156185137153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43938</th>\n",
              "      <td>Pro</td>\n",
              "      <td>Dear @realDonaldTrump,\\nYeah right. Human Medi...</td>\n",
              "      <td>791307031919550464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43939</th>\n",
              "      <td>Pro</td>\n",
              "      <td>What will your respective parties do to preven...</td>\n",
              "      <td>791316857403936768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43940</th>\n",
              "      <td>News</td>\n",
              "      <td>RT @MikkiL: UN Poll Shows Climate Change Is th...</td>\n",
              "      <td>791357509101621249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43941</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>RT @taehbeingextra: i still can$q$t believe th...</td>\n",
              "      <td>791390042136641537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43942</th>\n",
              "      <td>Pro</td>\n",
              "      <td>@Likeabat77 @zachhaller \\n\\nThe wealthy + foss...</td>\n",
              "      <td>791401610308038656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43943 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29c7795c-3583-41ca-8a63-e12ab963fb32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29c7795c-3583-41ca-8a63-e12ab963fb32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29c7795c-3583-41ca-8a63-e12ab963fb32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "climate = pd.read_csv(\"climate.csv\")\n",
        "climate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4H5XRUog_as5"
      },
      "outputs": [],
      "source": [
        "climate_text = climate.message\n",
        "climate_labels = pd.get_dummies(climate.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GXTd0E9wBZQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9961a11f-cb27-4e9a-cf71-7dd76c4b4ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.83715075 0.85454543 ... 0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(climate_text)\n",
        "\n",
        "# Directly get the one-hot binary representations.\n",
        "# Note that other vectorization modes than one-hot encoding are supported!\n",
        "one_hot_results = tokenizer.texts_to_matrix(climate_text, mode='tfidf')\n",
        "# let's look at an example of an encoding ...\n",
        "print(one_hot_results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "uTiI3Ejz_rRe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9d497f11-804d-41e9-83a3-5b799e03f472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Anti  Neutral  News  Pro\n",
              "34461     0        1     0    0\n",
              "20916     0        0     1    0\n",
              "14218     0        0     0    1\n",
              "30674     0        1     0    0\n",
              "32400     0        0     0    1\n",
              "...     ...      ...   ...  ...\n",
              "33649     0        0     0    1\n",
              "5523      0        0     0    1\n",
              "25031     0        0     0    1\n",
              "5638      0        0     0    1\n",
              "17989     0        0     1    0\n",
              "\n",
              "[8789 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f37303c4-2e64-4990-9bb3-98b370717f30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anti</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>News</th>\n",
              "      <th>Pro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34461</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20916</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14218</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30674</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32400</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33649</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5523</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25031</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5638</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17989</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8789 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f37303c4-2e64-4990-9bb3-98b370717f30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f37303c4-2e64-4990-9bb3-98b370717f30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f37303c4-2e64-4990-9bb3-98b370717f30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "climate_train_text, climate_test_text, climate_train_labels, climate_test_labels = train_test_split(one_hot_results, climate_labels, test_size = 0.2, random_state=42)\n",
        "climate_test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzPe1NnLpeG3"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>2. Create a deep learning densely connected network.</font> \n",
        "\n",
        "You can decide how many layers and how many nodes per layer. Keep in mind that for the imdb task the last layer was:\n",
        "\n",
        "```\n",
        "network.add(layers.Dense(1, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "The `1` was selected because we only had a binary choice (positive or negative). `sigmoid` was also selected because we had a binary choice.  This will not be the same for this task. In the imdb example, we used the binary_crossentropy loss function because, again, we only had a binary choice.\n",
        "\n",
        "Create the network, compile it, and fit it to the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "4_TOQQHKBKHG"
      },
      "outputs": [],
      "source": [
        "climnet = models.Sequential()\n",
        "climnet.add(layers.Dense(512, activation='relu', input_shape=(5000,)))\n",
        "climnet.add(layers.Dense(256, activation='relu'))\n",
        "climnet.add(layers.Dense(128, activation='relu'))\n",
        "climnet.add(layers.Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "g3MqPKtsEalS"
      },
      "outputs": [],
      "source": [
        "climnet.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ob7PnaBgFB__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df8aa52-d027-4b1d-e12a-38297f7d852d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.0376 - accuracy: 0.5730 - val_loss: 0.8477 - val_accuracy: 0.6670\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7196 - accuracy: 0.7173 - val_loss: 0.7195 - val_accuracy: 0.7134\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5583 - accuracy: 0.7882 - val_loss: 0.6899 - val_accuracy: 0.7229\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4486 - accuracy: 0.8367 - val_loss: 0.6890 - val_accuracy: 0.7332\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.3631 - accuracy: 0.8696 - val_loss: 0.7004 - val_accuracy: 0.7329\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2926 - accuracy: 0.8979 - val_loss: 0.7362 - val_accuracy: 0.7293\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2326 - accuracy: 0.9217 - val_loss: 0.7895 - val_accuracy: 0.7316\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1823 - accuracy: 0.9414 - val_loss: 0.8455 - val_accuracy: 0.7328\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1398 - accuracy: 0.9572 - val_loss: 0.9238 - val_accuracy: 0.7309\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1072 - accuracy: 0.9683 - val_loss: 0.9901 - val_accuracy: 0.7224\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0814 - accuracy: 0.9770 - val_loss: 1.0723 - val_accuracy: 0.7254\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0619 - accuracy: 0.9829 - val_loss: 1.1656 - val_accuracy: 0.7249\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0477 - accuracy: 0.9870 - val_loss: 1.2544 - val_accuracy: 0.7245\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 1.3643 - val_accuracy: 0.7278\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 1.4317 - val_accuracy: 0.7246\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 1.5053 - val_accuracy: 0.7198\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 1.5750 - val_accuracy: 0.7201\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 1.6477 - val_accuracy: 0.7238\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.6748 - val_accuracy: 0.7174\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 1.7348 - val_accuracy: 0.7150\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 1.8025 - val_accuracy: 0.7198\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 1.8309 - val_accuracy: 0.7158\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.8702 - val_accuracy: 0.7083\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 1.9203 - val_accuracy: 0.7198\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.9662 - val_accuracy: 0.7171\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 1.9528 - val_accuracy: 0.7138\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 1.9867 - val_accuracy: 0.7137\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 2.0035 - val_accuracy: 0.7161\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 2.0994 - val_accuracy: 0.7148\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 2.0472 - val_accuracy: 0.7171\n"
          ]
        }
      ],
      "source": [
        "history = climnet.fit(\n",
        "      climate_train_text, climate_train_labels,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_split=0.2,\n",
        "      validation_steps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMNg3FIoqrEE"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>2. Plot the accuracy and loss for both the training and validation sets.</font> \n",
        "\n",
        "Also, state in a few sentences what you see in the plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bBr_F10YFOzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c1092a69-256e-4e64-a565-6f9a76e99d92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph is very similar to the previous example. \n",
        "It shows large jumps in accuracy early on, and a stabilization at near 100% accuracy later.\n",
        "The validation loss shows a steady increase throughout the training process. I'm guessing the reason for this is that as the training process goes on, the model is more and more reinforced towards a certain \"perspective\", and any new data it see's probably comes at odds with what it already \"knows\". Essentially it's really good at classifying things it already knows, ie. overfitting."
      ],
      "metadata": {
        "id": "HkpOPfC7Se-8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qipxYocrmy6"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>4. Accuracy on the test data</font> \n",
        "\n",
        "What is the accuracy on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Kh9VDWCGFfGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045be970-ccd9-4667-c4ed-e7e46aa1b922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275/275 [==============================] - 1s 2ms/step - loss: 2.1243 - accuracy: 0.7181\n",
            "Accuracy:  0.7180566787719727\n"
          ]
        }
      ],
      "source": [
        "scoreSeg = climnet.evaluate(climate_test_text, climate_test_labels)\n",
        "print(\"Accuracy: \", scoreSeg[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6sHJ2hEryR3"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>5. Can you do better than the baseline accuracy? +5-10 xp</font> \n",
        "Can you create a network that has better accuracy than that shown in #4 above?\n",
        "\n",
        "You can change:\n",
        "\n",
        "* the number of layers, \n",
        "* the number of nodes in each layer\n",
        "* change the `num_words` used in the tokenizer\n",
        "* add one or more dropout layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=3000)\n",
        "tokenizer.fit_on_texts(climate_text)\n",
        "\n",
        "# Directly get the one-hot binary representations.\n",
        "# Note that other vectorization modes than one-hot encoding are supported!\n",
        "one_hot_results = tokenizer.texts_to_matrix(climate_text, mode='tfidf')\n",
        "# let's look at an example of an encoding ...\n",
        "print(one_hot_results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUP3KuTqUM0V",
        "outputId": "e3c6499f-70d3-4d8d-b765-9ee62c5236da"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.83715075 0.85454543 ... 0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climate_train_text, climate_test_text, climate_train_labels, climate_test_labels = train_test_split(one_hot_results, climate_labels, test_size = 0.2, random_state=42)\n",
        "climate_test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "onBIezJuUeg0",
        "outputId": "a766c5c5-02e1-4fd6-ba02-872365d4c225"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Anti  Neutral  News  Pro\n",
              "34461     0        1     0    0\n",
              "20916     0        0     1    0\n",
              "14218     0        0     0    1\n",
              "30674     0        1     0    0\n",
              "32400     0        0     0    1\n",
              "...     ...      ...   ...  ...\n",
              "33649     0        0     0    1\n",
              "5523      0        0     0    1\n",
              "25031     0        0     0    1\n",
              "5638      0        0     0    1\n",
              "17989     0        0     1    0\n",
              "\n",
              "[8789 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f545dcaa-91ce-4e2d-8d8c-e462fcb0ada0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anti</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>News</th>\n",
              "      <th>Pro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34461</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20916</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14218</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30674</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32400</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33649</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5523</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25031</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5638</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17989</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8789 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f545dcaa-91ce-4e2d-8d8c-e462fcb0ada0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f545dcaa-91ce-4e2d-8d8c-e462fcb0ada0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f545dcaa-91ce-4e2d-8d8c-e462fcb0ada0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "-0U5UMresDkj"
      },
      "outputs": [],
      "source": [
        "climnet2 = models.Sequential()\n",
        "climnet2.add(layers.Dropout(rate=.1, input_shape=(3000,)))\n",
        "climnet2.add(layers.Dense(300, activation='relu'))\n",
        "climnet2.add(layers.Dropout(rate=.1, input_shape=(300,)))\n",
        "climnet2.add(layers.Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climnet2.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6LiPac2_UnWI"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = climnet2.fit(\n",
        "      climate_train_text, climate_train_labels,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_split=0.2,\n",
        "      validation_steps=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVXyEITUqf5",
        "outputId": "c1cf8682-7485-4da2-f069-3df8ebe1b904"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.1177 - accuracy: 0.5342 - val_loss: 0.9474 - val_accuracy: 0.6228\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.8847 - accuracy: 0.6482 - val_loss: 0.8272 - val_accuracy: 0.6742\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.7777 - accuracy: 0.6959 - val_loss: 0.7633 - val_accuracy: 0.6968\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.7095 - accuracy: 0.7225 - val_loss: 0.7268 - val_accuracy: 0.7093\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.7379 - val_loss: 0.7043 - val_accuracy: 0.7164\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7540 - val_loss: 0.6910 - val_accuracy: 0.7229\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.7647 - val_loss: 0.6819 - val_accuracy: 0.7264\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7760 - val_loss: 0.6768 - val_accuracy: 0.7288\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.7785 - val_loss: 0.6735 - val_accuracy: 0.7332\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7903 - val_loss: 0.6723 - val_accuracy: 0.7338\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7948 - val_loss: 0.6733 - val_accuracy: 0.7340\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.8013 - val_loss: 0.6724 - val_accuracy: 0.7338\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.8050 - val_loss: 0.6743 - val_accuracy: 0.7346\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.8126 - val_loss: 0.6760 - val_accuracy: 0.7349\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.8178 - val_loss: 0.6776 - val_accuracy: 0.7350\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.8173 - val_loss: 0.6790 - val_accuracy: 0.7359\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.8246 - val_loss: 0.6825 - val_accuracy: 0.7363\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8307 - val_loss: 0.6842 - val_accuracy: 0.7372\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8299 - val_loss: 0.6875 - val_accuracy: 0.7373\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8375 - val_loss: 0.6915 - val_accuracy: 0.7349\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8394 - val_loss: 0.6935 - val_accuracy: 0.7353\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8446 - val_loss: 0.6990 - val_accuracy: 0.7362\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8462 - val_loss: 0.6999 - val_accuracy: 0.7362\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8528 - val_loss: 0.7025 - val_accuracy: 0.7372\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8532 - val_loss: 0.7072 - val_accuracy: 0.7377\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8585 - val_loss: 0.7099 - val_accuracy: 0.7387\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8581 - val_loss: 0.7135 - val_accuracy: 0.7377\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8615 - val_loss: 0.7182 - val_accuracy: 0.7365\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8661 - val_loss: 0.7201 - val_accuracy: 0.7370\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8690 - val_loss: 0.7218 - val_accuracy: 0.7363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scoreSeg = climnet2.evaluate(climate_test_text, climate_test_labels)\n",
        "print(\"Accuracy: \", scoreSeg[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avxtsk4SYgZb",
        "outputId": "45a23730-7f7f-45f3-e076-8c19092f3022"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275/275 [==============================] - 1s 2ms/step - loss: 0.7181 - accuracy: 0.7439\n",
            "Accuracy:  0.7438843846321106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: \n",
        "My highest accuracy was the above 74.39%.\n",
        "I tested various model structures and token num_words amounts and the best model I could come up with had two dropout layers and one input and output layer. Through my search online I learned that overfitting and the inability of a model to generalize can be due to a number of things, but in this case it is likely that the original model was to complex for the data. So in essence the model was picking up on features that weren't necessary in the prediction of the sentiment of a tweet. What I did was drastically reduce the complexity of the model, picked less words to be used in the tokenizer and include dropout layers that dropped random nodes or features between layers. The dropout layers in theory would help the removal of unneccesary dimensionality. "
      ],
      "metadata": {
        "id": "7qURTJ6W2vta"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8Sp9K-M2woU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}